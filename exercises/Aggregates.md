# Aggregate Exercises

## Exercise 1: Customer Purchase Summary

Given a dataset of customer purchases, aggregate the total number of purchases and the total revenue generated by each customer.

### Data

```
customer_id,purchase_date,amount
1,2023-01-01,100.50
2,2023-01-01,150.00
1,2023-01-02,200.75
3,2023-01-01,120.00
2,2023-01-03,300.00
1,2023-01-04,50.25
3,2023-01-05,80.00
```

### Solution

```python
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

# Create Spark session
spark = SparkSession.builder.appName("CustomerPurchaseSummary").getOrCreate()

# Load data
df = spark.read.csv("purchases.csv", header=True, inferSchema=True)

# Aggregate data
result = df.groupBy("customer_id").agg(
    F.count("amount").alias("total_purchases"),
    F.sum("amount").alias("total_revenue")
)

result.show()
```

## Exercise 2: Monthly Sales Analysis

Calculate the total sales amount for each month in a given year and the average sale amount per transaction.

### Data

```
transaction_id,sale_date,amount
1,2023-01-15,100.00
2,2023-01-20,200.00
3,2023-02-15,300.00
4,2023-02-20,150.00
5,2023-03-05,400.00
6,2023-01-25,50.00
7,2023-03-10,250.00
```

### Solution

```python
# Load data
df = spark.read.csv("sales.csv", header=True, inferSchema=True)

# Extract month from sale_date
df = df.withColumn("month", F.month("sale_date"))

# Aggregate data
result = df.groupBy("month").agg(
    F.sum("amount").alias("total_sales"),
    F.avg("amount").alias("average_sale")
)

result.show()
```

## Exercise 3: Employee Performance Metrics

Calculate the average performance score for each department, along with the total number of employees in each department.

### Data

```
employee_id,department,performance_score
1,Sales,85
2,Sales,90
3,Marketing,78
4,Marketing,82
5,Engineering,95
6,Engineering,88
7,Sales,75
```

### Solution

```python
# Load data
df = spark.read.csv("employee_performance.csv", header=True, inferSchema=True)

# Aggregate data
result = df.groupBy("department").agg(
    F.avg("performance_score").alias("average_performance"),
    F.count("employee_id").alias("total_employees")
)

result.show()
```

## Exercise 4: Product Rating Analysis

Find the average rating and the total number of ratings for each product.

### Data

```
product_id,rating
1,5
2,4
1,3
3,2
2,5
3,4
1,4
3,5
```

### Solution

```python
# Load data
df = spark.read.csv("product_ratings.csv", header=True, inferSchema=True)

# Aggregate data
result = df.groupBy("product_id").agg(
    F.avg("rating").alias("average_rating"),
    F.count("rating").alias("total_ratings")
)

result.show()
```

## Exercise 5: Traffic Incident Analysis

### Data

```
incident_id,location,severity
1,Location A,3
2,Location B,2
3,Location A,1
4,Location C,4
5,Location B,3
6,Location A,2
7,Location C,3
```

### Solution

```python
# Load data
df = spark.read.csv("traffic_incidents.csv", header=True, inferSchema=True)

# Aggregate data
result = df.groupBy("location").agg(
    F.count("incident_id").alias("total_incidents"),
    F.avg("severity").alias("average_severity")
)

result.show()
```
